{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75aaadeb-3fe0-45c6-966b-8e27a45aafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 4000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")  # Replace with the actual dataset name\n",
    "\n",
    "# Check the structure\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d1a9303-6a39-4f2b-bb28-5c19149bb30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                               | 0/4000 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Provided `function` which is applied to all elements of table returns a variable of type <class 'tuple'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], tf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n\u001b[0;32m---> 20\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mwith_options(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions())\n\u001b[1;32m     21\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Split training and validation\u001b[39;00m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3428\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3426\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3428\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3430\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3336\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3334\u001b[0m         updatable_types \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pl\u001b[38;5;241m.\u001b[39mDataFrame,)\n\u001b[1;32m   3335\u001b[0m     update_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, updatable_types)\n\u001b[0;32m-> 3336\u001b[0m     \u001b[43mvalidate_function_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m update_data:\n\u001b[1;32m   3338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Nothing to update, let's move on\u001b[39;00m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3272\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.validate_function_output\u001b[0;34m(processed_inputs, indices)\u001b[0m\n\u001b[1;32m   3270\u001b[0m     allowed_processed_inputs_types \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pl\u001b[38;5;241m.\u001b[39mDataFrame,)\n\u001b[1;32m   3271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, allowed_processed_inputs_types):\n\u001b[0;32m-> 3272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3273\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `function` which is applied to all elements of table returns a variable of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(processed_inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3274\u001b[0m     )\n\u001b[1;32m   3275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indices, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, Mapping):\n\u001b[1;32m   3276\u001b[0m     allowed_batch_return_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mSeries)\n",
      "\u001b[0;31mTypeError\u001b[0m: Provided `function` which is applied to all elements of table returns a variable of type <class 'tuple'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Hugging Face dataset\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Convert to TensorFlow Dataset and resize images\n",
    "def preprocess(example):\n",
    "    image = tf.image.resize(example['image'], (150, 150)) / 255.0  # Rescale to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "train_data = dataset['train'].map(preprocess).with_options(tf.data.Options())\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Split training and validation\n",
    "train_size = int(0.8 * len(dataset['train']))\n",
    "validation_data = train_data.skip(train_size).take(len(dataset['train']) - train_size)\n",
    "train_data = train_data.take(train_size)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_small.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, validation_data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y for x, y in validation_data], axis=0)\n",
    "    y_pred = model.predict(validation_data)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4645df-e699-4aab-ad25-8df1f3c4667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████| 4000/4000 [09:59<00:00,  6.68 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'with_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label}\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_options\u001b[49m(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions())\n\u001b[1;32m     24\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Model Definition\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'with_options'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    # Resize and normalize the image\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data = dataset['train'].map(preprocess).with_options(tf.data.Options())\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=50,\n",
    "    validation_data=train_data,  # for illustration; ideally, use a separate validation set\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e744aa-6253-4824-8bf6-c7307025362e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dataset.shuffle() got an unexpected keyword argument 'buffer_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[1;32m     23\u001b[0m train_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(preprocess)\n\u001b[0;32m---> 24\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Model Definition\u001b[39;00m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     28\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m     29\u001b[0m     MaxPooling2D(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m ])\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/fingerprint.py:442\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dataset.shuffle() got an unexpected keyword argument 'buffer_size'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    # Resize and normalize the image\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data = dataset['train'].map(preprocess)\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=50,\n",
    "    validation_data=train_data,  # for illustration; ideally, use a separate validation set\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7ebaf0-3d13-4f28-b436-67871d39b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████| 4000/4000 [08:10<00:00,  8.16 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'with_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label}  \u001b[38;5;66;03m# Return a dictionary\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to the training data\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_options\u001b[49m(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions())\n\u001b[1;32m     23\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Split training and validation datasets\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'with_options'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}  # Return a dictionary\n",
    "\n",
    "# Apply preprocessing to the training data\n",
    "train_data = dataset['train'].map(preprocess).with_options(tf.data.Options())\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Split training and validation datasets\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_data = train_data.skip(train_size)\n",
    "train_data = train_data.take(train_size)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d436e8d6-4a1e-4303-ab73-a68072a7cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batching examples: 100%|██████| 4000/4000 [05:05<00:00, 13.08 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'prefetch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to the training data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(preprocess)  \u001b[38;5;66;03m# Removed with_options\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Split training and validation datasets\u001b[39;00m\n\u001b[1;32m     26\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'prefetch'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}  # Return a dictionary\n",
    "\n",
    "# Apply preprocessing to the training data\n",
    "train_data = dataset['train'].map(preprocess)  # Removed with_options\n",
    "train_data = train_data.shuffle(seed=42).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Split training and validation datasets\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_data = train_data.skip(train_size)\n",
    "train_data = train_data.take(train_size)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102f7d96-0962-40c9-ae4c-f5a679600b7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Called a Tensorflow-specific function but Tensorflow is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(preprocess)  \u001b[38;5;66;03m# Removed with_options\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Convert to TensorFlow Dataset\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_data_tf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the input columns\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the label columns\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Split training and validation datasets\u001b[39;00m\n\u001b[1;32m     33\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data))\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:398\u001b[0m, in \u001b[0;36mTensorflowDatasetMixin.to_tf_dataset\u001b[0;34m(self, batch_size, columns, shuffle, collate_fn, drop_remainder, collate_fn_args, label_cols, prefetch, num_workers, num_test_batches)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalled a Tensorflow-specific function but Tensorflow is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(label_cols, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(label_cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    402\u001b[0m ):\n\u001b[1;32m    403\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of `to_tf_dataset` will change when a passing single element list for `labels` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`columns` in the next datasets version. To return a tuple structure rather than dict, pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Called a Tensorflow-specific function but Tensorflow is not installed."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}  # Return a dictionary\n",
    "\n",
    "# Apply preprocessing to the training data\n",
    "train_data = dataset['train'].map(preprocess)  # Removed with_options\n",
    "\n",
    "# Convert to TensorFlow Dataset\n",
    "train_data_tf = train_data.to_tf_dataset(\n",
    "    columns=['image'],  # Specify the input columns\n",
    "    label_cols=['label'],  # Specify the label columns\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "# Split training and validation datasets\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_data = train_data_tf.skip(train_size)\n",
    "train_data_tf = train_data_tf.take(train_size)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data_tf,\n",
    "    validation_data=validation_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030a5a30-a65f-4902-8814-012e8522bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c48d86-e84f-4114-b5bb-b8b6789d1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1000.1573, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b543a8b-148f-4e83-961a-be5e307abe65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Called a Tensorflow-specific function but Tensorflow is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(preprocess)  \u001b[38;5;66;03m# Removed with_options\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Convert to TensorFlow Dataset\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_data_tf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the input columns\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the label columns\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Split training and validation datasets\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data))\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:398\u001b[0m, in \u001b[0;36mTensorflowDatasetMixin.to_tf_dataset\u001b[0;34m(self, batch_size, columns, shuffle, collate_fn, drop_remainder, collate_fn_args, label_cols, prefetch, num_workers, num_test_batches)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalled a Tensorflow-specific function but Tensorflow is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(label_cols, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(label_cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    402\u001b[0m ):\n\u001b[1;32m    403\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of `to_tf_dataset` will change when a passing single element list for `labels` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`columns` in the next datasets version. To return a tuple structure rather than dict, pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Called a Tensorflow-specific function but Tensorflow is not installed."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"pantelism/cats-vs-dogs\")\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(example):\n",
    "    image = tf.image.resize(example['image'], (150, 150))\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    return {'image': image, 'label': label}  # Return a dictionary\n",
    "\n",
    "# Apply preprocessing to the training data\n",
    "train_data = dataset['train'].map(preprocess)  # Removed with_options\n",
    "\n",
    "# Convert to TensorFlow Dataset\n",
    "train_data_tf = train_data.to_tf_dataset(\n",
    "    columns=['image'],  # Specify the input columns\n",
    "    label_cols=['label'],  # Specify the label columns\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=lambda x: {'image': tf.stack([item['image'] for item in x]),\n",
    "                           'label': tf.stack([item['label'] for item in x])},\n",
    ")\n",
    "\n",
    "\n",
    "# Split training and validation datasets\n",
    "train_size = int(0.8 * len(train_data))\n",
    "validation_data = train_data_tf.skip(train_size)\n",
    "train_data_tf = train_data_tf.take(train_size)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data_tf,\n",
    "    validation_data=validation_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_model.h5')\n",
    "\n",
    "# Plotting training history\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Confusion Matrix and ROC Curve\n",
    "def evaluate_model(model, data):\n",
    "    # Get true labels and predictions\n",
    "    y_true = np.concatenate([y['label'].numpy() for y in data], axis=0)\n",
    "    y_pred = np.concatenate([model.predict(y['image']) for y in data], axis=0)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e4b04a0-134f-4dc9-a694-732887583d8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4268408557.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    In this notebook, we implement two popular explainability methods for convolutional neural networks (CNNs): **Integrated Gradients** and **Grad-CAM**. These methods help us understand how the model makes its predictions by highlighting the important regions in the input images.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Cats vs. Dogs Classification with Explainability\n",
    "\n",
    "In this notebook, we implement two popular explainability methods for convolutional neural networks (CNNs): **Integrated Gradients** and **Grad-CAM**. These methods help us understand how the model makes its predictions by highlighting the important regions in the input images.\n",
    "\n",
    "We will use the trained model from our previous work on the Cats vs. Dogs classification task. The model achieved a certain level of accuracy using data augmentation, and now we will explain its decisions.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [Load the Model](#load-the-model)\n",
    "3. [Integrated Gradients](#integrated-gradients)\n",
    "4. [Grad-CAM](#grad-cam)\n",
    "5. [Results and Conclusion](#results-and-conclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed3f8d4-ed01-4196-bf87-8cccfa227e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GradCam' from 'captum.attr' (/Users/vi.rubio/eng-ai-agents/venv/lib/python3.11/site-packages/captum/attr/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntegratedGradients\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradCam\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize_image_attr\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GradCam' from 'captum.attr' (/Users/vi.rubio/eng-ai-agents/venv/lib/python3.11/site-packages/captum/attr/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradCam\n",
    "from captum.attr import visualize_image_attr\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load('cats_and_dogs_model.pth')  # Load your saved model\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing function for images\n",
    "def preprocess(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Function to visualize Integrated Gradients\n",
    "def visualize_integrated_gradients(image_tensor):\n",
    "    ig = IntegratedGradients(model)\n",
    "    # Make sure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the image\n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    # Compute attributions\n",
    "    attr_ig = ig.attribute(image_tensor, target=1)  # Assuming '1' is the target class\n",
    "\n",
    "    # Visualize\n",
    "    attr_ig_np = attr_ig.squeeze().detach().numpy().transpose(1, 2, 0)  # Convert to HWC\n",
    "    visualize_image_attr(attr_ig_np, method='heat_map', sign='all', title='Integrated Gradients Attribution')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize Grad-CAM\n",
    "def visualize_gradcam(image_tensor):\n",
    "    grad_cam = GradCam(model, model.conv2)  # Adjust layer as per your model architecture\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the image\n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    # Compute Grad-CAM attributions\n",
    "    cam = grad_cam.attribute(image_tensor, target=1)\n",
    "\n",
    "    # Rescale to [0, 1]\n",
    "    cam_np = cam.squeeze().detach().numpy()\n",
    "    cam_np = np.maximum(cam_np, 0)\n",
    "    cam_np /= cam_np.max()  # Normalize\n",
    "\n",
    "    # Convert to heatmap\n",
    "    heatmap = cv2.resize(cam_np, (150, 150))  # Resize to original image size\n",
    "    heatmap = np.uint8(255 * heatmap)  # Convert to 8-bit image\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # Apply color map\n",
    "\n",
    "    # Overlay heatmap on original image\n",
    "    original_image_np = image_tensor.squeeze().permute(1, 2, 0).numpy()  # Convert to HWC\n",
    "    overlay = cv2.addWeighted(original_image_np, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Load your image using PIL or any other method\n",
    "from PIL import Image\n",
    "image = Image.open(\"path_to_your_image.jpg\")\n",
    "\n",
    "visualize_integrated_gradients(image)\n",
    "visualize_gradcam(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c90585b8-7fef-48d3-8cdd-9723e901fefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'visualize_image_attr' from 'captum.attr' (/Users/vi.rubio/eng-ai-agents/venv/lib/python3.11/site-packages/captum/attr/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntegratedGradients\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerGradCam\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize_image_attr\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_and_dogs_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Load your saved model\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'visualize_image_attr' from 'captum.attr' (/Users/vi.rubio/eng-ai-agents/venv/lib/python3.11/site-packages/captum/attr/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerGradCam\n",
    "from captum.attr import visualize_image_attr\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load('cats_and_dogs_model.pth')  # Load your saved model\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing function for images\n",
    "def preprocess(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Function to visualize Integrated Gradients\n",
    "def visualize_integrated_gradients(image_tensor):\n",
    "    ig = IntegratedGradients(model)\n",
    "    model.eval()\n",
    "    \n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    attr_ig = ig.attribute(image_tensor, target=1)\n",
    "\n",
    "    attr_ig_np = attr_ig.squeeze().detach().numpy().transpose(1, 2, 0)\n",
    "    visualize_image_attr(attr_ig_np, method='heat_map', sign='all', title='Integrated Gradients Attribution')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize Grad-CAM\n",
    "def visualize_gradcam(image_tensor):\n",
    "    # Use LayerGradCam for Grad-CAM\n",
    "    layer_grad_cam = LayerGradCam(model, model.conv2)  # Adjust layer as per your model architecture\n",
    "    model.eval()\n",
    "    \n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    cam = layer_grad_cam.attribute(image_tensor, target=1)\n",
    "\n",
    "    cam_np = cam.squeeze().detach().numpy()\n",
    "    cam_np = np.maximum(cam_np, 0)\n",
    "    cam_np /= cam_np.max()\n",
    "\n",
    "    heatmap = plt.cm.jet(cam_np)[:, :, :3]  # Create a heatmap using Matplotlib\n",
    "\n",
    "    original_image_np = image_tensor.squeeze().permute(1, 2, 0).numpy()\n",
    "    overlay = (heatmap * 0.5 + original_image_np * 0.5)\n",
    "\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "from PIL import Image\n",
    "image = Image.open(\"path_to_your_image.jpg\")\n",
    "\n",
    "visualize_integrated_gradients(image)\n",
    "visualize_gradcam(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c8c5e6a-d3ad-47f8-8aa1-652b4f41b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qs/5tb486nj6bv4jc33tdzjs8qr0000gn/T/ipykernel_34644/938220871.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('cats_and_dogs_model.pth')  # Load your saved model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cats_and_dogs_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization \u001b[38;5;28;01mas\u001b[39;00m viz  \u001b[38;5;66;03m# Updated import for visualization\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load your trained model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcats_and_dogs_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load your saved model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Preprocessing function for images\u001b[39;00m\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/eng-ai-agents/venv/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cats_and_dogs_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerGradCam\n",
    "from captum.attr import visualization as viz  # Updated import for visualization\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load('cats_and_dogs_model.pth')  # Load your saved model\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing function for images\n",
    "def preprocess(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Function to visualize Integrated Gradients\n",
    "def visualize_integrated_gradients(image_tensor):\n",
    "    ig = IntegratedGradients(model)\n",
    "    model.eval()\n",
    "    \n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    attr_ig = ig.attribute(image_tensor, target=1)\n",
    "\n",
    "    attr_ig_np = attr_ig.squeeze().detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    # Visualize the Integrated Gradients attribution\n",
    "    viz.visualize_image_attr(attr_ig_np, method='heat_map', sign='all', title='Integrated Gradients Attribution')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Function to visualize Grad-CAM\n",
    "def visualize_gradcam(image_tensor):\n",
    "    # Use LayerGradCam for Grad-CAM\n",
    "    layer_grad_cam = LayerGradCam(model, model.conv2)  # Adjust layer as per your model architecture\n",
    "    model.eval()\n",
    "    \n",
    "    image_tensor = preprocess(image_tensor)\n",
    "\n",
    "    cam = layer_grad_cam.attribute(image_tensor, target=1)\n",
    "\n",
    "    cam_np = cam.squeeze().detach().numpy()\n",
    "    cam_np = np.maximum(cam_np, 0)\n",
    "    cam_np /= cam_np.max()\n",
    "\n",
    "    heatmap = plt.cm.jet(cam_np)[:, :, :3]  # Create a heatmap using Matplotlib\n",
    "\n",
    "    original_image_np = image_tensor.squeeze().permute(1, 2, 0).numpy()\n",
    "    overlay = (heatmap * 0.5 + original_image_np * 0.5)\n",
    "\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "from PIL import Image\n",
    "image = Image.open(\"path_to_your_image.jpg\")\n",
    "\n",
    "visualize_integrated_gradients(image)\n",
    "visualize_gradcam(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686be73-8f8a-45a9-aa31-d7ee30723e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
